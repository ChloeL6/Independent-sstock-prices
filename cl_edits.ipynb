{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/14 17:01:38 WARN Utils: Your hostname, DESKTOP-SU1U0NI resolves to a loopback address: 127.0.1.1; using 172.21.244.112 instead (on interface eth0)\n",
      "23/02/14 17:01:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/14 17:01:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "import os \n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as sf      # sf = spark functions\n",
    "import pyspark.sql.types as st          # st = spark types\n",
    "import datetime as dt\n",
    "\n",
    "spark = SparkSession.builder.master('local').getOrCreate()\n",
    "\n",
    "# spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|   Yearmon|CPI|\n",
      "+----------+---+\n",
      "|01-01-1913|9.8|\n",
      "|01-02-1913|9.8|\n",
      "|01-03-1913|9.8|\n",
      "|01-04-1913|9.8|\n",
      "|01-05-1913|9.7|\n",
      "+----------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|Year|Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec|\n",
      "+----+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|1948|3.4|3.8|4.0|3.9|3.5|3.6|3.6|3.9|3.8|3.7|3.8|4.0|\n",
      "|1949|4.3|4.7|5.0|5.3|6.1|6.2|6.7|6.8|6.6|7.9|6.4|6.6|\n",
      "|1950|6.5|6.4|6.3|5.8|5.5|5.4|5.0|4.5|4.4|4.2|4.2|4.3|\n",
      "|1951|3.7|3.4|3.4|3.1|3.0|3.2|3.1|3.1|3.3|3.5|3.5|3.1|\n",
      "|1952|3.2|3.1|2.9|2.9|3.0|3.0|3.2|3.4|3.1|3.0|2.8|2.7|\n",
      "+----+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data'\n",
    "\n",
    "cpi_file = 'US-CPI.csv'\n",
    "unemp_file = 'USUnemployment.csv'\n",
    "\n",
    "c_schema = 'Yearmon string, CPI float'\n",
    "u_schema = 'Year int, Jan float ,Feb float ,Mar float,Apr float ,May float,Jun float ,Jul float ,Aug float ,Sep float,Oct float,Nov float,Dec float'\n",
    "\n",
    "cpi_df = spark.read.csv(os.path.join(data_dir, cpi_file), schema=c_schema, header=True, enforceSchema=True)\n",
    "unemp_df = spark.read.csv(os.path.join(data_dir, unemp_file), schema=u_schema, header=True, enforceSchema=True)\n",
    "\n",
    "cpi_df.show(5)\n",
    "unemp_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: string (nullable = true)\n",
      " |-- cpi: float (nullable = true)\n",
      "\n",
      "+----+---+-----+----+\n",
      "|year|cpi|month|date|\n",
      "+----+---+-----+----+\n",
      "|1913|9.8|   01|  01|\n",
      "|1913|9.8|   01|  02|\n",
      "|1913|9.8|   01|  03|\n",
      "|1913|9.8|   01|  04|\n",
      "|1913|9.7|   01|  05|\n",
      "+----+---+-----+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----+------------------+\n",
      "|year|          avg(cpi)|\n",
      "+----+------------------+\n",
      "|1953|26.766666571299236|\n",
      "|1957|28.091666380564373|\n",
      "|1987|           113.625|\n",
      "|1956|27.183333079020183|\n",
      "|1936|13.866666634877523|\n",
      "+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,avg\n",
    "# rename cols in cpi df\n",
    "\n",
    "for column in cpi_df.columns: \n",
    "  cpi_df = cpi_df.withColumnRenamed(column, column.lower())\n",
    "\n",
    "cpi_df = cpi_df.withColumnRenamed('yearmon', 'year')\n",
    "\n",
    "# split year column into month, date, year columns\n",
    "split_cpi_df = cpi_df.withColumn(\"month\", sf.split(sf.col('year'), \"-\").getItem(0))\\\n",
    "              .withColumn('date', sf.split(sf.col('year'), \"-\").getItem(1))\\\n",
    "              .withColumn('year', sf.split(sf.col('year'), \"-\").getItem(2))\n",
    "\n",
    "# cast year col to int for groupby method\n",
    "# cpi_df = cpi_df.withColumn('year', sf.col('year').cast('int'))\n",
    "\n",
    "# rename cols in unemployment df\n",
    "for column in unemp_df.columns: \n",
    "  unemp_df = unemp_df.withColumnRenamed(column, column.lower())\n",
    "\n",
    "# calculate avg unemployment rate per year\n",
    "udf_avg = sf.udf(lambda array: sum(array)/len(array))\n",
    "unemp_df = unemp_df.withColumn(\"avg_unemp_rate_per_year\", udf_avg(sf.array('Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec')).cast('float'))\n",
    "\n",
    "# calculate avg inflation rate per year\n",
    "avg_cpi_df = split_cpi_df.groupBy(sf.col('year')) \\\n",
    "                .agg(sf.avg(sf.col('cpi')))\n",
    "\n",
    "# avg_cpi_df.show(truncate=False)\n",
    "cpi_df.printSchema()\n",
    "split_cpi_df.show(5)\n",
    "avg_cpi_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>cpi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1913</td>\n",
       "      <td>9.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1914</td>\n",
       "      <td>10.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1915</td>\n",
       "      <td>10.108333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1916</td>\n",
       "      <td>10.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1917</td>\n",
       "      <td>12.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1918</td>\n",
       "      <td>15.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1919</td>\n",
       "      <td>17.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1920</td>\n",
       "      <td>20.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1921</td>\n",
       "      <td>17.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1922</td>\n",
       "      <td>16.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year        cpi\n",
       "0  1913   9.883333\n",
       "1  1914  10.016667\n",
       "2  1915  10.108333\n",
       "3  1916  10.883333\n",
       "4  1917  12.825000\n",
       "5  1918  15.041667\n",
       "6  1919  17.333333\n",
       "7  1920  20.041667\n",
       "8  1921  17.850000\n",
       "9  1922  16.750000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read and rename cpi file / parse_dates=['Yearmon']\n",
    "cpi  = pd.read_csv(os.path.join(data_dir, cpi_file), header=0)\n",
    "cpi = cpi.rename(columns={'Yearmon': 'year', 'CPI': 'cpi'})\n",
    "cpi[['month', 'date', 'year']] = cpi.year.str.split(\"-\", expand=True)\n",
    "\n",
    "# read and rename unemployment file\n",
    "unemp = pd.read_csv(os.path.join(data_dir, unemp_file), header=0)\n",
    "unemp.columns = unemp.columns.str.lower()\n",
    "\n",
    "\n",
    "# calculate the avg yearly unemp. rate\n",
    "columns = ['jan',\t'feb',\t'mar',\t'apr',\t'may'\t,'jun',\t'jul',\t'aug',\t'sep',\t'oct',\t'nov',\t'dec']\n",
    "unemp['avg_unemp_per_year']  = unemp[columns].mean(axis=1)\n",
    "avg_unemp_per_year  = unemp[['year', 'avg_unemp_per_year']]\n",
    "\n",
    "# calculate the avg yearly cpi rate\n",
    "avg_cpi_per_year = cpi.groupby('year').mean('cpi')\n",
    "avg_cpi_per_year = avg_cpi_per_year.reset_index()\n",
    "\n",
    "avg_unemp_per_year.head(5)\n",
    "avg_cpi_per_year.head(10)\n",
    "# unemp.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# create bigquery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# create full table id\n",
    "project_id = \"team-week-3\"\n",
    "dataset_id = \"tech_stocks_world_events\"\n",
    "\n",
    "cpi_table_name = \"cpi_rates\"\n",
    "unemp_table_name = \"unemployment_rates\"\n",
    "\n",
    "# table_id = f\"{project_id}.{dataset_id}.{table_name}\"\n",
    "\n",
    "\n",
    "# create bigquery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# create our own bigquery schema\n",
    "avg_cpi_schema = [\n",
    "    bigquery.SchemaField(\"year\", \"INT\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"avg_cpi_per_year\", \"FLOAT\", mode=\"REQUIRED\")]\n",
    "\n",
    "avg_emp_schema = [\n",
    "    bigquery.SchemaField(\"year\", \"INT\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"avg_cpi_per_year\", \"FLOAT\", mode=\"REQUIRED\")]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13cd2dfbaa0c360159abf2d98dc2f30be3ac863f44bedcc9d13de3e4ef3ae6ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
